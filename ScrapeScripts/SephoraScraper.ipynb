{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fetching reviews :: 100% (226 of 226) |##| Elapsed Time: 1:05:12 Time:  1:05:12\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from progressbar import progressbar\n",
    "import requests\n",
    "import math\n",
    "\n",
    "\n",
    "class SephoraDataCollector:\n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        initialize object with urls\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #url to return all products in foundation category\n",
    "        self.product_url = 'https://www.sephora.com/api/catalog/categories/cat60004/products?currentPage={current_page}&pageSize=999999999&content=true&includeRegionsMap=true'\n",
    "        \n",
    "        #url to return all reviews for specific product\n",
    "        self.review_url = 'https://api.bazaarvoice.com/data/reviews.json?Filter=ProductId%3A{product_id}&Sort=Helpfulness%3Adesc&Limit=100&Offset={offset}&Include=Products%2CComments&Stats=Reviews&passkey=rwbw526r2e7spptqd2qzbkp7&apiversion=5.4'\n",
    "\n",
    "    def fetch_and_write_data(self, file_path='sephora_review_db.csv'):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        retrieves reviews and writes to csv\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #get all product ids to iterate over\n",
    "        product_ids = self._fetch_all_product_ids()\n",
    "        \n",
    "        #row names in csv\n",
    "        key_fields = ['brand', 'name', 'rating', 'skin_type', 'eye_color', 'skin_concerns', 'incentivized_review',\n",
    "                      'skin_tone', 'age', 'beauty_insider', 'user_name', 'price']\n",
    "        \n",
    "        #create csv file\n",
    "        with open(file_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=key_fields)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            #iterate over every product id to get all reviews and write to csv\n",
    "            for p in progressbar(product_ids, prefix='fetching reviews :: '):\n",
    "                batch_review = self._fetch_all_reviews(p)\n",
    "                for batch in batch_review:\n",
    "                    writer.writerow(batch)\n",
    "    \n",
    "    \n",
    "    def _fetch_all_product_ids(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        returns all product ids from url\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #set current_page to 0 in url \n",
    "        sub = {'current_page': 0}\n",
    "        \n",
    "        #read json\n",
    "        data = self._fetch(self.product_url.format(**sub))\n",
    "        \n",
    "        #extract productId from dictionary\n",
    "        all_data = [d['productId'] for d in data['products']]\n",
    "        \n",
    "        return all_data\n",
    "    \n",
    "    def _fetch_all_prices(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        returns all prices for each product\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #set current_page to 0 in url \n",
    "        sub = {'current_page': 0}\n",
    "        \n",
    "        #read json\n",
    "        data = self._fetch(self.product_url.format(**sub))\n",
    "        \n",
    "        #extract prices from dictionary\n",
    "        prices = [d['currentSku']['listPrice'] for d in data['products']]\n",
    "        \n",
    "        return prices\n",
    "         \n",
    "        \n",
    "    \n",
    "    def _fetch_all_brand_names(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        returns all brand names for each product\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #set current_page to 0 in url\n",
    "        sub = {'current_page': 0}\n",
    "        \n",
    "        #read json\n",
    "        data = self._fetch(self.product_url.format(**sub))\n",
    "        \n",
    "        #extract brand names from dictionary\n",
    "        brand_names = [d['brandName'] for d in data['products']]\n",
    "\n",
    "        return brand_names\n",
    "    \n",
    "    def _fetch_all_prod_names(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        returns name of each product in list\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #set current_page to 0 in url\n",
    "        sub = {'current_page': 0}\n",
    "        \n",
    "        #read json\n",
    "        data = self._fetch(self.product_url.format(**sub))\n",
    "        \n",
    "        #extract product names from dictionary\n",
    "        prod_names = [d['displayName'] for d in data['products']]\n",
    "\n",
    "        return prod_names\n",
    "            \n",
    "\n",
    "    def _fetch_all_reviews(self, product_id):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        reads in url and product_id\n",
    "        \n",
    "        returns necessary information for every review for product_id\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #get list of prices, brands, and product names in order of iteration\n",
    "        price_dat = self._fetch_all_prices()\n",
    "        brand_dat = self._fetch_all_brand_names()\n",
    "        prod_dat = self._fetch_all_prod_names()\n",
    "        \n",
    "        #get all product ids for iteration\n",
    "        prod_ids = self._fetch_all_product_ids()\n",
    "        \n",
    "        #read json of first page of review information for product_id\n",
    "        dat = self._fetch(self.review_url.format(**{'offset': 0, 'product_id': product_id}))\n",
    "        \n",
    "        #initialize empty list\n",
    "        all_reviews = []\n",
    "        \n",
    "        #limit: max is 100 - means that only 100 reviews per page\n",
    "        #offset: which set of 100 (or whatever specified limit) we are on\n",
    "        #iterate over offset in url by getting total number of reviews from json and dividing by 100\n",
    "        for offset in range(math.floor((dat['TotalResults'])/100) + 1):\n",
    "            \n",
    "            #get data for specific offset value and product_id\n",
    "            data = self._fetch(self.review_url.format(**{'offset': offset, 'product_id': product_id}))\n",
    "            \n",
    "            #this table remains constant for specific product_id but still needs to be appended to row\n",
    "            table1 = {'brand': brand_dat[prod_ids.index(product_id)],\n",
    "                      'name': prod_dat[prod_ids.index(product_id)],\n",
    "                      'price': price_dat[prod_ids.index(product_id)]}\n",
    "            \n",
    "            #this table is review specific information\n",
    "            for review in data['Results']:\n",
    "                table2 = {'user_name': review.get('UserNickname', ''),\n",
    "                          'rating': review.get('Rating', ''),\n",
    "                          'skin_type': self.nget(review, '', 'ContextDataValues', 'skinType', 'Value'),\n",
    "                          'eye_color': self.nget(review, '', 'ContextDataValues', 'eyeColor', 'Value'),\n",
    "                          'skin_concerns': self.nget(review, '', 'ContextDataValues', 'skinConcerns', 'Value'),\n",
    "                          'incentivized_review': self.nget(review, '', 'ContextDataValues', 'IncentivizedReview', 'Value'),\n",
    "                          'skin_tone': self.nget(review, '', 'ContextDataValues', 'skinTone', 'Value'),\n",
    "                          'age': self.nget(review, '', 'ContextDataValues', 'age', 'Value'),\n",
    "                          'beauty_insider': self.nget(review, '', 'ContextDataValues', 'beautyInsider', 'Value')}\n",
    "                \n",
    "                #concatenate and append both to make one row in csv\n",
    "                all_reviews.append({**table1, **table2})\n",
    "        \n",
    "        return all_reviews[:dat['TotalResults']]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _fetch(url):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        returns json dictionary from url\n",
    "        \n",
    "        \"\"\"\n",
    "        r = requests.get(url)\n",
    "        return json.loads(r.content)\n",
    "\n",
    "    @staticmethod\n",
    "    def nget(dct, default=None, *keys):\n",
    "        \n",
    "        \"\"\"\n",
    "        returns specified values from dictionary\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        for key in keys:\n",
    "            try:\n",
    "                dct = dct[key]\n",
    "            except KeyError:\n",
    "                return default\n",
    "        return dct\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    s = SephoraDataCollector()\n",
    "    s.fetch_and_write_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
